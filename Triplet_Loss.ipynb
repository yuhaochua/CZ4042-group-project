{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.io as scp\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from dataset import train_dataset, test_dataset, val_dataset\n",
    "from torch.utils.data import Dataset  # Import the Dataset class\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                        [0.229, 0.224, 0.225])])\n",
    "\n",
    "testval_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.Flowers102(root='./data', split='train', download=True, transform=train_transform)\n",
    "val_dataset = torchvision.datasets.Flowers102(root='./data', split='val', download=True, transform=testval_transform)\n",
    "test_dataset = torchvision.datasets.Flowers102(root='./data', split='test', download=True, transform=testval_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.labels = np.array([item[1] for item in dataset])\n",
    "        self.label_to_indices = {label: np.where(self.labels == label)[0] for label in np.unique(self.labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor, anchor_label = self.dataset[idx]\n",
    "        positive_idx = idx\n",
    "\n",
    "        while positive_idx == idx:\n",
    "            positive_idx = random.choice(self.label_to_indices[anchor_label])\n",
    "\n",
    "        negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "        while negative_label == anchor_label:\n",
    "            negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "\n",
    "        negative_idx = random.choice(self.label_to_indices[negative_label])\n",
    "\n",
    "        positive, _ = self.dataset[positive_idx]\n",
    "        negative, _ = self.dataset[negative_idx]\n",
    "\n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256  # Adjust the batch size as needed\n",
    "\n",
    "train_triplet_dataset = TripletDataset(train_dataset)\n",
    "train_triplet_loader = DataLoader(train_triplet_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    # Calculate Euclidean distances between the anchor, positive, and negative embeddings\n",
    "    distance_positive = F.pairwise_distance(anchor, positive, p=2)\n",
    "    distance_negative = F.pairwise_distance(anchor, negative, p=2)\n",
    "\n",
    "    # Calculate the triplet loss\n",
    "    loss = torch.clamp(distance_positive - distance_negative + margin, min=0.0)\n",
    "    \n",
    "    # Return the average triplet loss over the batch\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optimizer,criterion = mobilenet()\n",
    "for anchor, positive, negative in train_triplet_loader:\n",
    "    # Forward pass to get embeddings for anchor, positive, and negative samples\n",
    "    anchor_emb = model(anchor)\n",
    "    positive_emb = model(positive)\n",
    "    negative_emb = model(negative)\n",
    "\n",
    "    # Calculating triplet loss using the custom triplet loss function\n",
    "    loss = triplet_loss(anchor_emb, positive_emb, negative_emb)\n",
    "\n",
    "    # Backpropagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Implement the evaluation here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
